# Comparing `tmp/dg_face_tracking-0.0.7-py3-none-any.whl.zip` & `tmp/dg_face_tracking-0.0.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,70 +1,70 @@
-Zip file size: 125279 bytes, number of entries: 68
--rw-r--r--  2.0 unx      617 b- defN 24-Apr-04 00:53 dg_face_tracking/DataFaceApp.py
--rw-r--r--  2.0 unx      210 b- defN 24-Apr-04 00:53 dg_face_tracking/__init__.py
--rw-r--r--  2.0 unx      216 b- defN 24-Apr-04 00:53 dg_face_tracking/_version.py
--rw-r--r--  2.0 unx     2615 b- defN 24-Apr-04 00:53 dg_face_tracking/config_rt.py
--rw-r--r--  2.0 unx     1931 b- defN 24-Apr-04 00:53 dg_face_tracking/embeds_compare.py
--rw-r--r--  2.0 unx     2579 b- defN 24-Apr-04 00:53 dg_face_tracking/embeds_estimate.py
--rw-r--r--  2.0 unx     3473 b- defN 24-Apr-04 00:53 dg_face_tracking/estimate_accuracy.py
--rw-r--r--  2.0 unx     8408 b- defN 24-Apr-04 00:53 dg_face_tracking/face_tracker_controller.py
--rw-r--r--  2.0 unx     1050 b- defN 24-Apr-04 00:53 dg_face_tracking/track_faces.py
--rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/__init__.py
--rw-r--r--  2.0 unx     1642 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/consumer.py
--rw-r--r--  2.0 unx      764 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/consumer_factory.py
--rw-r--r--  2.0 unx     4687 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/embeds_writer.py
--rw-r--r--  2.0 unx     3965 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/lancedb_writer.py
--rw-r--r--  2.0 unx     4865 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/localdb_writer.py
--rw-r--r--  2.0 unx     6353 b- defN 24-Apr-04 00:53 dg_face_tracking/Consumers/pairwise_stats.py
--rw-r--r--  2.0 unx     1368 b- defN 24-Apr-04 00:53 dg_face_tracking/Data/basedata.py
--rw-r--r--  2.0 unx     2804 b- defN 24-Apr-04 00:53 dg_face_tracking/Data/face_data.py
--rw-r--r--  2.0 unx     1656 b- defN 24-Apr-04 00:53 dg_face_tracking/Data/frame_data.py
--rw-r--r--  2.0 unx     4660 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/CameraSource.py
--rw-r--r--  2.0 unx     6933 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/DatasetSource.py
--rw-r--r--  2.0 unx    12206 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/FolderSource.py
--rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/__init__.py
--rw-r--r--  2.0 unx     5366 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/datasource.py
--rw-r--r--  2.0 unx      841 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/datasource_factory.py
--rw-r--r--  2.0 unx    24168 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/face_tracker.py
--rw-r--r--  2.0 unx    30622 b- defN 24-Apr-04 00:53 dg_face_tracking/DataSource/face_tracker_demo.py
--rw-r--r--  2.0 unx     1572 b- defN 24-Apr-04 00:53 dg_face_tracking/Database/DBAdapter.py
--rw-r--r--  2.0 unx    11902 b- defN 24-Apr-04 00:53 dg_face_tracking/Database/LocalDBAdapter.py
--rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 00:53 dg_face_tracking/Database/__init__.py
--rw-r--r--  2.0 unx     8548 b- defN 24-Apr-04 00:53 dg_face_tracking/Database/vectstore.py
--rw-r--r--  2.0 unx    13408 b- defN 24-Apr-04 00:53 dg_face_tracking/Frontend/DataFaceDoc.py
--rw-r--r--  2.0 unx      908 b- defN 24-Apr-04 00:53 dg_face_tracking/Frontend/DataFaceFrontend.py
--rw-r--r--  2.0 unx     5965 b- defN 24-Apr-04 00:53 dg_face_tracking/Frontend/DataFaceView.py
--rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 00:53 dg_face_tracking/Frontend/__init__.py
--rw-r--r--  2.0 unx      305 b- defN 24-Apr-04 00:53 dg_face_tracking/Frontend/frontend_factory.py
--rw-r--r--  2.0 unx     5194 b- defN 24-Apr-04 00:53 dg_face_tracking/Frontend/main_window.py
--rw-r--r--  2.0 unx     1583 b- defN 24-Apr-04 00:53 dg_face_tracking/Process/dg_process.py
--rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/__init__.py
--rw-r--r--  2.0 unx     4294 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/deepface_embedder.py
--rw-r--r--  2.0 unx    13784 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/face_detector.py
--rw-r--r--  2.0 unx     9165 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/face_embedder.py
--rw-r--r--  2.0 unx     7113 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/lancedb_searcher.py
--rw-r--r--  2.0 unx     5357 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/processor.py
--rw-r--r--  2.0 unx     1171 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/processor_factory.py
--rw-r--r--  2.0 unx     4267 b- defN 24-Apr-04 00:53 dg_face_tracking/Processors/tracker.py
--rw-r--r--  2.0 unx     1212 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/__init__.py
--rw-r--r--  2.0 unx    13749 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/camera_motion.py
--rw-r--r--  2.0 unx    18314 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/distances.py
--rw-r--r--  2.0 unx    10088 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/filter.py
--rw-r--r--  2.0 unx    11844 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/metrics.py
--rw-r--r--  2.0 unx    39484 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/tracker.py
--rw-r--r--  2.0 unx     3866 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/utils.py
--rw-r--r--  2.0 unx    13518 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/video.py
--rw-r--r--  2.0 unx      397 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/__init__.py
--rw-r--r--  2.0 unx     3754 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/absolute_grid.py
--rw-r--r--  2.0 unx    11207 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/color.py
--rw-r--r--  2.0 unx     7694 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/draw_boxes.py
--rw-r--r--  2.0 unx    11955 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/draw_points.py
--rw-r--r--  2.0 unx    10620 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/drawer.py
--rw-r--r--  2.0 unx     6002 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/fixed_camera.py
--rw-r--r--  2.0 unx     8593 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/path.py
--rw-r--r--  2.0 unx      912 b- defN 24-Apr-04 00:53 dg_face_tracking/norfair/drawing/utils.py
--rw-r--r--  2.0 unx     5224 b- defN 24-Apr-04 00:53 dg_face_tracking-0.0.7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-04 00:53 dg_face_tracking-0.0.7.dist-info/WHEEL
--rw-r--r--  2.0 unx       74 b- defN 24-Apr-04 00:53 dg_face_tracking-0.0.7.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       17 b- defN 24-Apr-04 00:53 dg_face_tracking-0.0.7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6542 b- defN 24-Apr-04 00:53 dg_face_tracking-0.0.7.dist-info/RECORD
-68 files, 413943 bytes uncompressed, 114629 bytes compressed:  72.3%
+Zip file size: 125960 bytes, number of entries: 68
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-04 22:39 dg_face_tracking/DataFaceApp.py
+-rw-r--r--  2.0 unx      210 b- defN 24-Apr-04 22:39 dg_face_tracking/__init__.py
+-rw-r--r--  2.0 unx      216 b- defN 24-Apr-04 22:39 dg_face_tracking/_version.py
+-rw-r--r--  2.0 unx     2615 b- defN 24-Apr-04 22:39 dg_face_tracking/config_rt.py
+-rw-r--r--  2.0 unx     1931 b- defN 24-Apr-04 22:39 dg_face_tracking/embeds_compare.py
+-rw-r--r--  2.0 unx     2579 b- defN 24-Apr-04 22:39 dg_face_tracking/embeds_estimate.py
+-rw-r--r--  2.0 unx     3473 b- defN 24-Apr-04 22:39 dg_face_tracking/estimate_accuracy.py
+-rw-r--r--  2.0 unx     8408 b- defN 24-Apr-04 22:39 dg_face_tracking/face_tracker_controller.py
+-rw-r--r--  2.0 unx     1464 b- defN 24-Apr-04 22:39 dg_face_tracking/track_faces.py
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/__init__.py
+-rw-r--r--  2.0 unx     1642 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/consumer.py
+-rw-r--r--  2.0 unx      764 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/consumer_factory.py
+-rw-r--r--  2.0 unx     4687 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/embeds_writer.py
+-rw-r--r--  2.0 unx     3965 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/lancedb_writer.py
+-rw-r--r--  2.0 unx     4865 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/localdb_writer.py
+-rw-r--r--  2.0 unx     6353 b- defN 24-Apr-04 22:39 dg_face_tracking/Consumers/pairwise_stats.py
+-rw-r--r--  2.0 unx     1368 b- defN 24-Apr-04 22:39 dg_face_tracking/Data/basedata.py
+-rw-r--r--  2.0 unx     2804 b- defN 24-Apr-04 22:39 dg_face_tracking/Data/face_data.py
+-rw-r--r--  2.0 unx     1656 b- defN 24-Apr-04 22:39 dg_face_tracking/Data/frame_data.py
+-rw-r--r--  2.0 unx     4660 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/CameraSource.py
+-rw-r--r--  2.0 unx     6933 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/DatasetSource.py
+-rw-r--r--  2.0 unx    12206 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/FolderSource.py
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/__init__.py
+-rw-r--r--  2.0 unx     5366 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/datasource.py
+-rw-r--r--  2.0 unx      841 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/datasource_factory.py
+-rw-r--r--  2.0 unx    24168 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/face_tracker.py
+-rw-r--r--  2.0 unx    31736 b- defN 24-Apr-04 22:39 dg_face_tracking/DataSource/face_tracker_demo.py
+-rw-r--r--  2.0 unx     1572 b- defN 24-Apr-04 22:39 dg_face_tracking/Database/DBAdapter.py
+-rw-r--r--  2.0 unx    11902 b- defN 24-Apr-04 22:39 dg_face_tracking/Database/LocalDBAdapter.py
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 22:39 dg_face_tracking/Database/__init__.py
+-rw-r--r--  2.0 unx     9561 b- defN 24-Apr-04 22:39 dg_face_tracking/Database/vectstore.py
+-rw-r--r--  2.0 unx    13408 b- defN 24-Apr-04 22:39 dg_face_tracking/Frontend/DataFaceDoc.py
+-rw-r--r--  2.0 unx      908 b- defN 24-Apr-04 22:39 dg_face_tracking/Frontend/DataFaceFrontend.py
+-rw-r--r--  2.0 unx     5965 b- defN 24-Apr-04 22:39 dg_face_tracking/Frontend/DataFaceView.py
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 22:39 dg_face_tracking/Frontend/__init__.py
+-rw-r--r--  2.0 unx      305 b- defN 24-Apr-04 22:39 dg_face_tracking/Frontend/frontend_factory.py
+-rw-r--r--  2.0 unx     5194 b- defN 24-Apr-04 22:39 dg_face_tracking/Frontend/main_window.py
+-rw-r--r--  2.0 unx     1583 b- defN 24-Apr-04 22:39 dg_face_tracking/Process/dg_process.py
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/__init__.py
+-rw-r--r--  2.0 unx     4294 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/deepface_embedder.py
+-rw-r--r--  2.0 unx    13784 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/face_detector.py
+-rw-r--r--  2.0 unx     9165 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/face_embedder.py
+-rw-r--r--  2.0 unx     7113 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/lancedb_searcher.py
+-rw-r--r--  2.0 unx     5357 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/processor.py
+-rw-r--r--  2.0 unx     1171 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/processor_factory.py
+-rw-r--r--  2.0 unx     4267 b- defN 24-Apr-04 22:39 dg_face_tracking/Processors/tracker.py
+-rw-r--r--  2.0 unx     1212 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/__init__.py
+-rw-r--r--  2.0 unx    13749 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/camera_motion.py
+-rw-r--r--  2.0 unx    18314 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/distances.py
+-rw-r--r--  2.0 unx    10088 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/filter.py
+-rw-r--r--  2.0 unx    11844 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/metrics.py
+-rw-r--r--  2.0 unx    39668 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/tracker.py
+-rw-r--r--  2.0 unx     3866 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/utils.py
+-rw-r--r--  2.0 unx    13518 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/video.py
+-rw-r--r--  2.0 unx      397 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/__init__.py
+-rw-r--r--  2.0 unx     3754 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/absolute_grid.py
+-rw-r--r--  2.0 unx    11207 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/color.py
+-rw-r--r--  2.0 unx     7694 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/draw_boxes.py
+-rw-r--r--  2.0 unx    11955 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/draw_points.py
+-rw-r--r--  2.0 unx    10620 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/drawer.py
+-rw-r--r--  2.0 unx     6002 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/fixed_camera.py
+-rw-r--r--  2.0 unx     8593 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/path.py
+-rw-r--r--  2.0 unx      912 b- defN 24-Apr-04 22:39 dg_face_tracking/norfair/drawing/utils.py
+-rw-r--r--  2.0 unx     5224 b- defN 24-Apr-04 22:39 dg_face_tracking-0.0.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-04 22:39 dg_face_tracking-0.0.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx       74 b- defN 24-Apr-04 22:39 dg_face_tracking-0.0.9.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       17 b- defN 24-Apr-04 22:39 dg_face_tracking-0.0.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6542 b- defN 24-Apr-04 22:39 dg_face_tracking-0.0.9.dist-info/RECORD
+68 files, 416668 bytes uncompressed, 115310 bytes compressed:  72.3%
```

## zipnote {}

```diff
@@ -183,23 +183,23 @@
 
 Filename: dg_face_tracking/norfair/drawing/path.py
 Comment: 
 
 Filename: dg_face_tracking/norfair/drawing/utils.py
 Comment: 
 
-Filename: dg_face_tracking-0.0.7.dist-info/METADATA
+Filename: dg_face_tracking-0.0.9.dist-info/METADATA
 Comment: 
 
-Filename: dg_face_tracking-0.0.7.dist-info/WHEEL
+Filename: dg_face_tracking-0.0.9.dist-info/WHEEL
 Comment: 
 
-Filename: dg_face_tracking-0.0.7.dist-info/entry_points.txt
+Filename: dg_face_tracking-0.0.9.dist-info/entry_points.txt
 Comment: 
 
-Filename: dg_face_tracking-0.0.7.dist-info/top_level.txt
+Filename: dg_face_tracking-0.0.9.dist-info/top_level.txt
 Comment: 
 
-Filename: dg_face_tracking-0.0.7.dist-info/RECORD
+Filename: dg_face_tracking-0.0.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dg_face_tracking/_version.py

```diff
@@ -2,9 +2,9 @@
 # _version.py: package version
 #
 # Copyright DeGirum Corporation 2024
 # All rights reserved
 #
 
 # >>> increment version here vvv
-__version_info__ = ("0", "0", "7")
+__version_info__ = ("0", "0", "9")
 __version__ = ".".join(__version_info__)
```

## dg_face_tracking/track_faces.py

```diff
@@ -6,30 +6,41 @@
 
 from .face_tracker_controller import FaceTrackerController
 
 
 def track_faces():
     default_deployment = "docker"
     default_config_name = ""
+    default_command = ""
 
     parser = argparse.ArgumentParser()
     parser.add_argument("-c", "--config",
                            help="main config file path",
                            default=default_config_name)
     parser.add_argument("-d", "--deployment",
                            choices=["cloud","local", "docker"],
                            help="deployment type: cloud or local",
                            default=default_deployment)
+    parser.add_argument("-e", "--exec",
+                           help="execute service command",
+                           choices=["delete_embeds"],
+                           default=default_config_name)
+    command = default_command
     try:
         args = parser.parse_args()
         config_name = args.config
         deployment = args.deployment
+        command = args.exec
     except Exception as e:
         pass
 
+    if command == "delete_embeds":
+        if os.path.isfile("embeds.db"):
+            os.remove("embeds.db")
+
     try:
         ft = FaceTrackerController(deployment, config_name)
         ft.run()
     except:
         print("DataFace: main: Failed to Config controller")
```

## dg_face_tracking/DataSource/face_tracker_demo.py

```diff
@@ -24,35 +24,38 @@
 from pathlib import Path
 Path(__file__).resolve()
 
 from ..config_rt import ConfigRT
 from ..Data.face_data import FaceData, FrameData, EmbeddedFaceData, LabelData
 from ..Database.vectstore import VectStore
 
-from ..norfair.tracker import Detection, Tracker, TrackedObject
+from ..norfair.tracker import Detection, Tracker, TrackedObject, set_global_count
 
 
 default_config = {
     'track_selected': False,
     'use_tracker': True,
     'use_embedder': True,
     'embeddings_time_step': 0.5,
     'show_scores': False,
     'detector_score_th': 0.6,
     'face_accept_th': 0.35,
+    'face_reject_th': 0.40,
     'start_paused': False,
 
     'show_landmarks': False,
     'use_landmarks': True,
     'use_normalization': False,
 
     'auto_labels': True,
 
     'save_video_path': "",
 
+    'db_path': "embeds.db",
+
     'camera':
         {
             'camera_id': 0,
             'fps': -1,
             'loop': False,
             'max_frames': -1,
             'show_frames': True,
@@ -281,49 +284,14 @@
         face_img = dst_image[int(bbox[1]):int(bbox[1]+dst_dsize[1]-1), int(bbox[0]):int(bbox[0]+dst_dsize[0]-1)]
     else:
         face_img = src_image[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]
 
     return face_img
 
 
-def open_video_stream(video_source: Union[int, str, Path]) -> cv2.VideoCapture:
-    """Open OpenCV video stream from camera with given identifier.
-
-    video_source - 0-based index for local cameras
-       or IP camera URL in the format "rtsp://<user>:<password>@<ip or hostname>",
-       or local video file path,
-       or URL to mp4 video file,
-       or YouTube video URL
-
-    Returns video stream object and closing it on exit
-    """
-
-    if isinstance(video_source, Path):
-        video_source = str(video_source)
-
-    if isinstance(video_source, str) and urllib.parse.urlparse(
-        video_source
-    ).hostname in (
-        "www.youtube.com",
-        "youtube.com",
-        "youtu.be",
-    ):  # if source is YouTube video
-        import pafy
-
-        video_source = pafy.new(video_source).getbest(preftype="mp4").url
-
-    stream = cv2.VideoCapture(video_source)  # type: ignore[arg-type]
-    if not stream.isOpened():
-        raise Exception(f"Error opening '{video_source}' video stream")
-    else:
-        print(f"Successfully opened video stream '{video_source}'")
-
-    return stream
-
-
 class FaceTrackerDemo(threading.Thread):
     def __init__(self, q_in=None, config_name=None):
         self.proc_id = "face_tracker"
         super(FaceTrackerDemo, self).__init__()
 
         self.deployment = os.environ['DG_DEPLOYMENT']
         self.cloud_token = degirum_tools.get_token() if self.deployment.lower() == "cloud" else ""
@@ -365,21 +333,23 @@
 
         self.detector_cfg: dict = {}
         self.detect_model = None
 
         self.tracker = Tracker(distance_function="euclidean", distance_threshold=100)
         self.result_queue = Queue()  # result queue
 
-        self.vstore = VectStore(max_size=16)  # 16 samples per track
+        self.vstore = VectStore(max_size=32)  # 32 samples per track
 
         # display thread
         self.display_thread = threading.Thread(target=self.result_process, args=())
 
         self.video_writer = None
 
+        self.db_path = ""
+
         print(f"FaceTrackerDemo: Starting name generator: {names_generator.generate_name(seed=42)}")
 
         # Starting real-time config tracking service
         if config_name is None:
             config_name = self.__class__.__name__
         try:
             self.config = ConfigRT(config_name)
@@ -431,23 +401,37 @@
         self.track_selected = self.config.get('track_selected',  default_config["track_selected"])
         self.use_tracker  = self.config.get('use_tracker',  default_config["use_tracker"])
         self.use_embedder = self.config.get('use_embedder', default_config["use_embedder"])
         self.embeddings_time_step = self.config.get('embeddings_time_step', default_config["embeddings_time_step"])
         self.show_scores = self.config.get('show_scores', default_config["show_scores"])
         self.detector_score_th = self.config.get('detector_score_th', default_config["detector_score_th"])
         self.face_accept_th = self.config.get('face_accept_th', default_config["face_accept_th"])
+        self.face_reject_th = self.config.get('face_reject_th', default_config["face_reject_th"])
 
         self.start_paused = self.config.get('start_paused', default_config["start_paused"])
 
         self.show_landmarks = self.config.get('show_landmarks', default_config["show_landmarks"])
         self.use_landmarks = self.config.get('use_landmarks', default_config["use_landmarks"])
         self.use_normalization = self.config.get('use_normalization', default_config["use_normalization"])
 
         self.auto_labels = self.config.get('auto_labels', default_config["auto_labels"])
 
+        self.db_path = self.config.get('db_path', default_config["db_path"])
+        try:
+            vstore = VectStore.load(self.db_path)
+            if vstore is not None:
+                global_id = vstore.max_metadata('global_id')
+                if global_id is not None:
+                    set_global_count(global_id + 1)
+                self.vstore = vstore
+
+        except Exception as e:
+            print(f"FaceTrackerDemo: apply_config: cannot load embeddings db: {e}")
+
+
         if self.video_writer is None:
             save_video_path = self.config.get('save_video_path', default_config["save_video_path"])
             if save_video_path != "":
                 self.video_writer = degirum_tools.create_video_writer(save_video_path, 640, 480)
 
         camera_cfg = self.config.get('camera', default_config["camera"])
         camera_id = camera_cfg['camera_id']
@@ -470,21 +454,15 @@
         Apply camera-related config
         """
         if camera_cfg != self.camera_cfg:
             default_cfg = default_config['camera']
             camera_id = camera_cfg.setdefault('camera_id', default_cfg['camera_id'])
             if self.stream is None or camera_id != self.camera_id:
                 #stream = cv2.VideoCapture(camera_id)
-                stream = open_video_stream(camera_id)
-                # Check if the video capturing object was initialized correctly
-                if not stream.isOpened():
-                    raise Exception(f"FaceTrackerDemo: init_camera {camera_id} cannot be initialized")
-                if self.stream is not None:
-                    self.stream.release()
-                self.stream = stream
+                self.open_video_stream(camera_id)
 
             self.fps = camera_cfg.setdefault('fps', default_cfg['fps'])
             self.loop = camera_cfg.setdefault('loop', default_cfg['loop'])
             self.max_frames = camera_cfg.setdefault('max_frames', default_cfg['max_frames'])
             self.is_file_input = os.path.exists(camera_id)
 
             # successfully applied camera_cfg
@@ -522,14 +500,53 @@
             self.detect_model = zoo.load_model(model_name)
             self.detect_model.image_backend = image_backend
             self.detect_model.input_numpy_colorspace = input_numpy_colorspace
 
             self.detector_cfg = detector_cfg
             print(f"*********** Applied Face Detector {model_name} with {self.fps} fps **********************")
 
+    def open_video_stream(self, video_source: Union[int, str, Path]) -> cv2.VideoCapture:
+        """Open OpenCV video stream from camera with given identifier.
+
+        video_source - 0-based index for local cameras
+           or IP camera URL in the format "rtsp://<user>:<password>@<ip or hostname>",
+           or local video file path,
+           or URL to mp4 video file,
+           or YouTube video URL
+
+        Returns video stream object and closing it on exit
+        """
+
+        if isinstance(video_source, Path):
+            video_source = str(video_source)
+
+        if isinstance(video_source, str) and urllib.parse.urlparse(
+                video_source
+        ).hostname in (
+                "www.youtube.com",
+                "youtube.com",
+                "youtu.be",
+        ):  # if source is YouTube video
+            import pafy
+
+            video_source = pafy.new(video_source).getbest(preftype="mp4").url
+
+        stream = cv2.VideoCapture(video_source)  # type: ignore[arg-type]
+        if not stream.isOpened():
+            raise Exception(f"Error opening '{video_source}' video stream")
+        else:
+            print(f"Successfully opened video stream '{video_source}'")
+
+        # Check if the video capturing object was initialized correctly
+        if not stream.isOpened():
+            raise Exception(f"FaceTrackerDemo: {video_source} cannot be initialized")
+        if self.stream is not None:
+            self.stream.release()
+        self.stream = stream
+
     def add_q_out(self, destination, q_out):
         self.q_out_map[destination] = q_out
 
     def start(self):
         self.display_thread.start()
         super(FaceTrackerDemo, self).start()
         self.start_time = time.time()
@@ -575,32 +592,36 @@
                     continue
                 if self.fps <= 0 or time_passed > time_lag:
                     prev_time = curr_time
                     ret, frame = self.stream.read()
                     if not ret:
                         if self.loop and self.is_file_input:
                             self.stream.set(cv2.CAP_PROP_POS_FRAMES, 0)
+                        print("Video Source: missing frame")
+                        self.open_video_stream(self.camera_id)
                         continue
                     self.frames_processed += 1
                     if self.frames_processed >= self.max_frames > 0:
                         raise EmptyQueue
                     if self.video_writer is not None:
                         self.video_writer.write(frame)
                     yield frame
                 elif self.fps > 0 and time_passed < time_lag:
                     time.sleep(time_lag - time_passed)
 
         except EmptyQueue:
             # No more data in dataset or max frames reached
             self.stop()
         finally:
+            print("Video Source: finally: releasing stream")
             self.stream.release()
 
     def result_process(self):
         win_capt = "Faces"
+        cv2.namedWindow(win_capt, cv2.WINDOW_NORMAL)
         while not self.is_stopped():
             result = self.result_queue.get()
             if result is None:
                 break
 
             self.re_id()
 
@@ -630,15 +651,14 @@
                 cv2.destroyWindow(win_capt)
                 self.send_data(None, "all")
                 self.stop()
                 break
             elif key == 32:
                 self.paused = True
 
-
     def objects2results(objects: List[TrackedObject]) -> list:
         results = []
         for obj in objects:
             points = obj.estimate.flatten().tolist()
             bbox = points[:4]
 
     def process_mouse_clicks(self, objects: List[TrackedObject]):
@@ -655,15 +675,14 @@
                             self.tracker.select_object(global_id=obj.global_id,  selected=True)
 
             except EmptyQueue:
                 break
             except Exception as e:
                 print("FaceTrackerDemo: process_mouse_clicks: " + str(e))
 
-
     def re_id(self):
         if self.q_in is None:
             return
         while True:
             data = None
             try:
                 data = self.q_in.get_nowait()
@@ -766,21 +785,23 @@
                     data.add_property("label", label)
                     data.add_property('face_score', score)
                     need2add = True
                     if stored_global_id != global_id:
                         need2add = False
                     # if self.track_selected and label != "" and label != "unknown":          # face identified!
                     #    data.add_property("label", label)
-                else:
+                elif score > self.face_reject_th:
                     if stored_global_id == global_id:
                         need2add = False
                     data.add_property('object_id', global_id)
                     #n_samples = vstore.class_size(object_id)
                     #face_image = data.get_face_image()
                     #cv2.imwrite(f"c:/Tmp/{object_id}_{n_samples}.jpg", face_image)
+                else:
+                    need2add = False
             else:
                 need2add = True
 
 
         label = data.get_property("label", "")
         if label == "" and auto_labels:
             label = generate_name(style='capital')
@@ -794,14 +815,15 @@
             # is_from_selected_track = data.get_property('selected', False)
             # if not self.track_selected or (self.track_selected and is_from_selected_track):
             if need2add: #(stored_global_id is None or (stored_global_id == global_id)):
                 # print(f"update_object_id: vstore.add object_id: {object_id},  label: {label}")
                 vstore.add(object_id, embeds, label, global_id=global_id)
                 #if stored_global_id is None:
                 vstore.add_metadata(object_id, global_id=global_id)
+                vstore.dump(self.db_path)
         else:
             # print(f"update_object_id: vstore.update object_id: {object_id},  label: {label}")
             vstore.update(object_id, label)
 
 
 def mouse_click(event, x, y,  flags, param: FaceTrackerDemo):
     if not isinstance(param, FaceTrackerDemo):
```

## dg_face_tracking/Database/vectstore.py

```diff
@@ -1,15 +1,20 @@
 import heapq
+import os.path
 from collections import deque
 import time
 import random
+import pickle
+from copy import deepcopy
 
 import math
 import numpy as np
 
+import threading
+
 from pathlib import Path
 Path(__file__).resolve()
 
 
 class VectStore:
     def __init__(self, max_size=16):
         self.max_size = max_size  # max number of vectors in a class
@@ -30,14 +35,46 @@
         max_size = 0
         for class_id in self.storage.keys():
             size = self.class_size(class_id)
             if size > max_size:
                 max_size = size
         return max_size
 
+    def max_metadata(self, key):
+        max_data = None
+        for val in self.metadata.values():
+            try:
+                data = val[key]
+                if max_data is None:
+                    max_data = data
+                else:
+                    if data is not None and max_data < data:
+                        max_data = data
+            except:
+                continue
+        return max_data
+
+    @classmethod
+    def load(cls, path):
+        if not os.path.isfile(path):
+            raise FileNotFoundError(f"VectStore: load: {path} does not exists")
+        with open(path, 'rb') as f:
+            db = pickle.load(f)
+            return db
+
+    def dump(self, path):
+        db_copy = deepcopy(self)
+
+        def run_dump(db, path):
+            with open(path, 'wb') as f:
+                pickle.dump(db, f)
+
+        dump_thread = threading.Thread(target=run_dump, args=(db_copy, path))
+        dump_thread.start()
+
     def size(self):
         _size = 0
         for vects in self.storage.values():
             _size += len(vects)
         return _size
 
     def add(self, class_id: str, vect: np.ndarray, label: str = "", **kvarg):
```

## dg_face_tracking/norfair/tracker.py

```diff
@@ -14,14 +14,20 @@
     ScalarDistance,
     get_distance_by_name,
 )
 from .filter import FilterFactory, OptimizedKalmanFilterFactory
 from .utils import validate_points, difference_between_smallest
 
 
+
+def set_global_count(cnt=0):
+    _TrackedObjectFactory.set_global_count(cnt)
+
+
+
 class Tracker:
     """
     The class in charge of performing the tracking of the detections produced by a detector.
 
     Parameters
     ----------
     distance_function : Union[str, Callable[[Detection, TrackedObject], float]]
@@ -433,14 +439,18 @@
         else:
             return [], []
 
 
 class _TrackedObjectFactory:
     global_count = 0
 
+    @classmethod
+    def set_global_count(cls, cnt):
+        _TrackedObjectFactory.global_count = cnt
+
     def __init__(self) -> None:
         self.count = 0
         self.initializing_count = 0
 
     def create(
         self,
         initial_detection: "Detection",
```

## Comparing `dg_face_tracking-0.0.7.dist-info/METADATA` & `dg_face_tracking-0.0.9.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dg_face_tracking
-Version: 0.0.7
+Version: 0.0.9
 Summary: DeGirum Face Tracking Application Package
 Home-page: https://github.com/degirum
 Author: DeGirum Corp.
 Author-email: support@degirum.com
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Development Status :: 3 - Alpha
 Classifier: Programming Language :: Python :: 3
```

## Comparing `dg_face_tracking-0.0.7.dist-info/RECORD` & `dg_face_tracking-0.0.9.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 dg_face_tracking/DataFaceApp.py,sha256=v4w12XC8tXZcHT9L_A93ceXCIf8h0clWDBZ10Jzd21Y,617
 dg_face_tracking/__init__.py,sha256=SWFsMrfNzomLor10-IgGeaE5V6fXMmSBegpH9Y0KY7I,210
-dg_face_tracking/_version.py,sha256=IbDJr5szZQ2jvhHTFpK1vd6CkK-bag-64WT9-Nnpt1o,216
+dg_face_tracking/_version.py,sha256=BvtWtDVTe5Q27TM_k7yaESLnLOilqLNaM_i3OVpSeIA,216
 dg_face_tracking/config_rt.py,sha256=uoh8Xf7N_y7Lg5gXhYPO-Msk0x54lXvkVRvBYB3qRME,2615
 dg_face_tracking/embeds_compare.py,sha256=ZdpoURTW9YlP8g0vFp7VB4C0gcunY-XFC2YoP9DCJ8o,1931
 dg_face_tracking/embeds_estimate.py,sha256=FRqmQsZTfm80kusa3HtjS1H3POK3q2pGXpdvi-Es42k,2579
 dg_face_tracking/estimate_accuracy.py,sha256=wSKDra0b8Ticmb_vLAtsheyknfBbnC1QOAoJJEqQU_Y,3473
 dg_face_tracking/face_tracker_controller.py,sha256=xmUqMdweNZkso3E8kLAxPGFiM7OzMa8ooR82rMqoBKA,8408
-dg_face_tracking/track_faces.py,sha256=pujzBXdUFl_-jmggTaIg7Xlg6p8jOsMb0M5Pai73sD4,1050
+dg_face_tracking/track_faces.py,sha256=tYhNK3w3oe06q_grNHitJFvWI8eWX6ClandelYOQ7Jo,1464
 dg_face_tracking/Consumers/__init__.py,sha256=ipTDkSDa3WQ4jgaDW3vOPTFVoGg64wDCpgw85hVUYJc,50
 dg_face_tracking/Consumers/consumer.py,sha256=qkaHcMMfNbKraTkvhvg8bCgryiWEdA-eM7xmSN_l-6g,1642
 dg_face_tracking/Consumers/consumer_factory.py,sha256=maekqM_-p7Pi3A7O-WrctsR_296oQj69ptPWDIzwvyk,764
 dg_face_tracking/Consumers/embeds_writer.py,sha256=jAm2Tx230AE30pmrfCnICoUZKHAGdEWoGdpfrWJ6b8k,4687
 dg_face_tracking/Consumers/lancedb_writer.py,sha256=2eCLYreHCu_U46OywKJp2lKS62seBpY3ia2cCGk-qhg,3965
 dg_face_tracking/Consumers/localdb_writer.py,sha256=RkuTEROlkmo5LwwjyJP5vgXvjb6XxPP2BSq4L8NNux8,4865
 dg_face_tracking/Consumers/pairwise_stats.py,sha256=hclyMemSHeh2nf8U9R9CStE2P2aXH1wkK-nfNoIHnwo,6353
@@ -20,19 +20,19 @@
 dg_face_tracking/DataSource/CameraSource.py,sha256=_eaYqJtf53WsRPkIHrzBwmPgV9y64KJgOOPbS-ylX2I,4660
 dg_face_tracking/DataSource/DatasetSource.py,sha256=yHXOgSxC6RVZ0Ad_H49xb3pg9hketVea7Rrc5sKc8Es,6933
 dg_face_tracking/DataSource/FolderSource.py,sha256=FuQ16DTMYqJUxTrLmr9CprNEZkukQO9oZPpgptHLG4M,12206
 dg_face_tracking/DataSource/__init__.py,sha256=ipTDkSDa3WQ4jgaDW3vOPTFVoGg64wDCpgw85hVUYJc,50
 dg_face_tracking/DataSource/datasource.py,sha256=SUQIE8tsEZ2L00xrKJ3ym1FM_m5u8q_GIu2wXk4P45M,5366
 dg_face_tracking/DataSource/datasource_factory.py,sha256=5uv-5YN3qbkEUb5pZ9XcNLk1AGzLp3YOtULadWaVY7k,841
 dg_face_tracking/DataSource/face_tracker.py,sha256=uYMyaoDxtv4YbFDA4NpzhK7332HIUR1gYN7r-2CqWs4,24168
-dg_face_tracking/DataSource/face_tracker_demo.py,sha256=Uf3eh6a-MfUXK4KGrVq3jsy8J21vF_4uLc9I7I41MUU,30622
+dg_face_tracking/DataSource/face_tracker_demo.py,sha256=EpKSxz6YvRAau11tASKjOnBSeLFQfxJvdULPxGyBUW4,31736
 dg_face_tracking/Database/DBAdapter.py,sha256=eh8PGvV_J-rn0S5VWKUpvY0nAbH-p1b_Zm_kOpQ2hh4,1572
 dg_face_tracking/Database/LocalDBAdapter.py,sha256=op37_5yYYWVdpgN0WLcTq65VBy1hOdIGL6adarAzzNY,11902
 dg_face_tracking/Database/__init__.py,sha256=ipTDkSDa3WQ4jgaDW3vOPTFVoGg64wDCpgw85hVUYJc,50
-dg_face_tracking/Database/vectstore.py,sha256=ZsaO5bt-YmgS1ZZiqlhaqjhchb05YMJ4jeY0WLKyjvQ,8548
+dg_face_tracking/Database/vectstore.py,sha256=7xCUuwEEbcljW53tmDyp-7YxUZ3cpw6BMu8rbs8TEGY,9561
 dg_face_tracking/Frontend/DataFaceDoc.py,sha256=pc5EuCJUC9dd6h0PS4iuXYxoGZH1LCszW73AiIE_dXw,13408
 dg_face_tracking/Frontend/DataFaceFrontend.py,sha256=TuTuH4-MR5Nmui3zNNuZwZnMdtK5Y6-x5vStQd-F3dw,908
 dg_face_tracking/Frontend/DataFaceView.py,sha256=QvnvgNkCiIvcOiFVRTO1NKN7JKRw---6fFVNcECfW9Q,5965
 dg_face_tracking/Frontend/__init__.py,sha256=ipTDkSDa3WQ4jgaDW3vOPTFVoGg64wDCpgw85hVUYJc,50
 dg_face_tracking/Frontend/frontend_factory.py,sha256=huoIZDgh4F42JZHKCDgscN31XS98h0-gs6atqH_tACY,305
 dg_face_tracking/Frontend/main_window.py,sha256=awGVtCIr3iyjyPjymeUEx0wNKl1Lwz9pq50YIbst5Bc,5194
 dg_face_tracking/Process/dg_process.py,sha256=xWARtSO2vZAbY26iWzTyrizsAyMhGprjFz-uR9ojmA4,1583
@@ -45,24 +45,24 @@
 dg_face_tracking/Processors/processor_factory.py,sha256=n_CJdIY5kAa1wsiG7UuZax0jNxPeqBCVVz3uL1sv0Fw,1171
 dg_face_tracking/Processors/tracker.py,sha256=RkHkn714_ATxo4NHy0uISYXIAiparFciD9mY78HY-9w,4267
 dg_face_tracking/norfair/__init__.py,sha256=z8ealWS11EsXOEnYEeeSxI0yuwSq5hF9mHNadReiynA,1212
 dg_face_tracking/norfair/camera_motion.py,sha256=pD5R9pM1YjnM1QLkppeuyK0wfiJbTOjhiehzW66jp8M,13749
 dg_face_tracking/norfair/distances.py,sha256=WlYadJM-cpFZKVYRr8PBeM476mIX-_-aZ3W1yiHcA1o,18314
 dg_face_tracking/norfair/filter.py,sha256=92MNGEe3S8rlwjGMgSkp1zxty5bTsplotrmKWpqf6MA,10088
 dg_face_tracking/norfair/metrics.py,sha256=q3HFaXoZc0WmYCV-jQH-stWOxMWy6Os0QMMrP_puJRo,11844
-dg_face_tracking/norfair/tracker.py,sha256=nj3IlEENt9iD_e_fYgAK7r4tFukAA_UZ0aewQmQXzBQ,39484
+dg_face_tracking/norfair/tracker.py,sha256=-oZCnKNsKhKEghkbntiArJB8ec6sb8QVfdkBSL1bmrE,39668
 dg_face_tracking/norfair/utils.py,sha256=o-q6xcx66D7IS8o4wIRa-d0mVcJ28CEjQerNKRb1NYw,3866
 dg_face_tracking/norfair/video.py,sha256=cxIkWAGdEaA6iDPc8QqyiQ78pd5dWqddZPsn5qjjjn8,13518
 dg_face_tracking/norfair/drawing/__init__.py,sha256=E7qsS86i3EUqmTTzGVboc_15fFOJc6Vajc3eqmW2npA,397
 dg_face_tracking/norfair/drawing/absolute_grid.py,sha256=_TjowEbSlqISs7twnIq1eJDM_CsGAeWjmc41309JLLE,3754
 dg_face_tracking/norfair/drawing/color.py,sha256=KIptTABXZ9X3-CHBi7O6dl46-8P9fSWUGIEIrfJfBT8,11207
 dg_face_tracking/norfair/drawing/draw_boxes.py,sha256=xdRiEGnOX4oxn1QOi956RKfOcoOKS2Na8PXLAgQ2FzA,7694
 dg_face_tracking/norfair/drawing/draw_points.py,sha256=gB5Dm4Eht-MAJRRqk0fGOoCNO28x6fHZyehPungMguc,11955
 dg_face_tracking/norfair/drawing/drawer.py,sha256=v0Ccce0OiWvUw04HKNpeyK7Rru1JjXiJlcB4PH4U7Wo,10620
 dg_face_tracking/norfair/drawing/fixed_camera.py,sha256=KAJCWYgym986hbzCBnr7kKa3A0qVYmTBoaL4LLq4O6E,6002
 dg_face_tracking/norfair/drawing/path.py,sha256=rA5EnnD_9Wj0OYv4h3-ccxn_VRrQqaNt8eFLAJXQc0k,8593
 dg_face_tracking/norfair/drawing/utils.py,sha256=g-mcTdpbfBQ1s-3Wy6CgfkCbImh1RGr3L7QZy2LjT10,912
-dg_face_tracking-0.0.7.dist-info/METADATA,sha256=qlcqJ4u5rJzW23ozPmBs64O0fdozNMJ0WH0A5tjoUEA,5224
-dg_face_tracking-0.0.7.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-dg_face_tracking-0.0.7.dist-info/entry_points.txt,sha256=ovgHU9wCkHRnHpdbwJosT_GZGHaoSIA6qUvn6gk_88U,74
-dg_face_tracking-0.0.7.dist-info/top_level.txt,sha256=a-hi1DQ_XruLP9Xm7BYdiR_88Vf2hlg9WabZkO1qJKQ,17
-dg_face_tracking-0.0.7.dist-info/RECORD,,
+dg_face_tracking-0.0.9.dist-info/METADATA,sha256=W9W4bZXAylGrfLEYRefJkhmbcqLhuWn897rsU-cC-FA,5224
+dg_face_tracking-0.0.9.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+dg_face_tracking-0.0.9.dist-info/entry_points.txt,sha256=ovgHU9wCkHRnHpdbwJosT_GZGHaoSIA6qUvn6gk_88U,74
+dg_face_tracking-0.0.9.dist-info/top_level.txt,sha256=a-hi1DQ_XruLP9Xm7BYdiR_88Vf2hlg9WabZkO1qJKQ,17
+dg_face_tracking-0.0.9.dist-info/RECORD,,
```

